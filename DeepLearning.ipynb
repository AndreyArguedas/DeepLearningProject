{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72775c7b-c998-4d00-ae37-ac5a31a7bea4",
   "metadata": {},
   "source": [
    "**Instituto Tecnológico de Costa Rica**\n",
    "\n",
    "**Escuela de Ingeniería en Computación**\n",
    "\n",
    "**Maestría Académica en Ciencias de la Computación**\n",
    "\n",
    "**Curso: Electiva Deep Learning**\n",
    "\n",
    "**Segundo Semestre 2024**\n",
    "\n",
    "**Profesor: Dr. Luis-Alexander Calvo-Valverde**\n",
    "\n",
    "---\n",
    "\n",
    "**Proyecto:**\n",
    "\n",
    "**Datos de la entrega:** Jueves 21 de noviembre 2024\n",
    "\n",
    "---\n",
    "\n",
    "**Estudiantes:**\n",
    "- Andrey Arguedas Espinoza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aeff1f-633e-4a58-aa54-f4b20d0f56c4",
   "metadata": {},
   "source": [
    "## • Prerequisites\n",
    "\n",
    "### - This version is implemented in Anaconda Navigator, if you want to to run it on Google Colab make sure to have the Pro version and mount the instance\n",
    "### - You need at leat 25GB RAM to run this project\n",
    "### - Add the dataset to the same path you have the notebook so it loads inmediately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0926cd-8409-454e-a37b-c54c65f033ff",
   "metadata": {},
   "source": [
    "## • Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e30144-164c-4b4f-8c81-e3f8ba13a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #Super important for these type of projects where plotting consumes a lot of resources\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, LSTM, TimeDistributed, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84a822-6c99-45c7-97fd-378b3902df57",
   "metadata": {},
   "source": [
    "### • Define global variables for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825869d8-194d-4e69-8796-b77319f5155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to UCF-101 dataset (replace with your path)\n",
    "dataset_path = './UCF101/UCF-101/'\n",
    "video_file = 'BaseballPitch/v_BaseballPitch_g07_c01.avi'  # example video file\n",
    "\n",
    "checkpoints_classification = 'checkpoints_classification'\n",
    "\n",
    "#checkpoint filename to save\n",
    "checkpoint_filename = 'detection_model{epoch:02d}.h5'\n",
    "#checkpoint filename to load\n",
    "checkpoint_filename_load = 'detection_model20.h5'\n",
    "\n",
    "# Specify frame size (width, height) for resizing\n",
    "frame_size = (60, 60)\n",
    "frames_per_video = 64\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecd608-c63f-4f36-978a-f76e6a3c56b4",
   "metadata": {},
   "source": [
    "### • Functions to show video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0ea8b6-cf7c-4ae0-a24f-b19c6940a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read video frames\n",
    "def read_video(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Function to visualize video frames in a multi-row grid\n",
    "def visualize_video(frames, num_frames=16, num_rows=2):\n",
    "    num_cols = num_frames // num_rows\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        if i < len(frames):\n",
    "            axes[row, col].imshow(frames[i])\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68033f1d-3b2a-4768-9142-809307a2091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize video\n",
    "#video_path = os.path.join(dataset_path, video_file)\n",
    "#frames = read_video(video_path)\n",
    "#visualize_video(frames, num_frames=64, num_rows=8)  # Display 64 frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a370ca2-141e-444d-b5c7-ea1780d8c5f2",
   "metadata": {},
   "source": [
    "### • Load the UFC-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9427a94-749e-45e5-b0ba-d377a0327d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ucf101_category(category, frame_size=frame_size):\n",
    "    \"\"\"\n",
    "    Load and resize videos from a specified category in the UCF-101 dataset.\n",
    "    \n",
    "    Args:\n",
    "    - category (str): Name of the category folder (e.g., 'ApplyEyeMakeup')\n",
    "    - frame_size (tuple): Desired frame size (width, height) for resizing\n",
    "    \n",
    "    Returns:\n",
    "    - videos (dict): A dictionary with video filenames as keys and lists of frames as values.\n",
    "    \"\"\"\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    videos = {}\n",
    "\n",
    "    for video_file in os.listdir(category_path):\n",
    "        if video_file.endswith('.avi'):\n",
    "            video_path = os.path.join(category_path, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # Resize the frame\n",
    "                frame = cv2.resize(frame, frame_size)\n",
    "                # Convert BGR to RGB for consistency with other libraries\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "            \n",
    "            cap.release()\n",
    "            videos[video_file] = frames  # Store frames by video filename\n",
    "    \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb9534f-3d86-4ed3-b191-43cebc3bbdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "category = 'Basketball'  # Replace with a category you want to load\n",
    "#videos = load_ucf101_category(category, frame_size=frame_size)\n",
    "\n",
    "# Checking one example video\n",
    "#for video_name, frames in videos.items():\n",
    "    #print(f\"Loaded video '{video_name}' with {len(frames)} frames resized to {frame_size}.\")\n",
    "    #visualize_video(frames, num_frames=64, num_rows=8)  # Display 64 frames\n",
    "    #break  # Just to print one example, remove if you want to list all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03181f57-72b3-4f1e-a0c7-7f5b8be56a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read video and resize frames\n",
    "def load_video(video_path, frame_size=frame_size, num_frames=frames_per_video):\n",
    "    cap = cv2.VideoCapture(video_path.numpy().decode('utf-8'))\n",
    "    frames = []\n",
    "    try:\n",
    "        while len(frames) < num_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    # If video is shorter than num_frames, repeat last frame\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return tf.convert_to_tensor(frames, dtype=tf.uint8)\n",
    "\n",
    "# Wrapper to make function compatible with tf.data\n",
    "def load_video_wrapper(video_path):\n",
    "    return tf.py_function(load_video, [video_path], tf.uint8)\n",
    "\n",
    "# Function to create dataset\n",
    "def create_ucf101_dataset(dataset_path, frame_size=frame_size, frames_per_video=frames_per_video, load_ratio = 2):\n",
    "    # Get list of all video file paths and corresponding labels\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(dataset_path))\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        for video_file in os.listdir(class_dir):\n",
    "            if video_file.endswith('.avi') and random.randint(0, load_ratio) == 1:\n",
    "                video_paths.append(os.path.join(class_dir, video_file))\n",
    "                labels.append(label)\n",
    "\n",
    "    # Convert to tf.data.Dataset\n",
    "    video_paths_ds = tf.data.Dataset.from_tensor_slices(video_paths)\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "    # Load and process videos\n",
    "    videos_ds = video_paths_ds.map(\n",
    "        lambda path: load_video_wrapper(path),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Combine videos and labels\n",
    "    dataset = tf.data.Dataset.zip((videos_ds, labels_ds))\n",
    "\n",
    "    # Batch, shuffle, and prefetch\n",
    "    dataset = dataset.shuffle(buffer_size=100).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, class_names, len(video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341bbbe8-8966-4545-a4d8-4d45d2cd475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a batch of videos in a grid format\n",
    "def plot_video_batch(video_batch, num_frames=frame_size, num_rows=8):\n",
    "    num_videos = video_batch.shape[0]  # Batch size\n",
    "    num_cols = num_frames // num_rows\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows * num_videos, num_cols, figsize=(20, 5 * num_rows * num_videos))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for v in range(num_videos):\n",
    "        frames = video_batch[v]\n",
    "        for i in range(num_frames):\n",
    "            row = (v * num_rows) + (i // num_cols)\n",
    "            col = i % num_cols\n",
    "            ax = axes[row, col] if num_videos > 1 else axes[col]\n",
    "            ax.imshow(frames[i].numpy())\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867fe786-6eda-426a-926f-ba9e8d2a51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset, class_names, amount_of_videos = create_ucf101_dataset(dataset_path, frame_size=frame_size, frames_per_video=frames_per_video, load_ratio = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5943643-9fef-4b24-b682-d29521a01703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video batch shape: (16, 64, 60, 60, 3)\n",
      "Label batch shape: (16,)\n",
      "tf.Tensor([5 4 0 5 6 2 1 0 1 6 4 6 7 2 5 4], shape=(16,), dtype=int32)\n",
      "Video batch shape: (16, 64, 60, 60, 3)\n",
      "Label batch shape: (16,)\n",
      "tf.Tensor([4 5 6 2 3 1 6 0 3 8 1 8 8 2 7 1], shape=(16,), dtype=int32)\n",
      "Video batch shape: (16, 64, 60, 60, 3)\n",
      "Label batch shape: (16,)\n",
      "tf.Tensor([7 8 2 9 2 5 8 9 8 6 4 8 7 9 1 7], shape=(16,), dtype=int32)\n",
      "Video batch shape: (16, 64, 60, 60, 3)\n",
      "Label batch shape: (16,)\n",
      "tf.Tensor([ 8  9  0 10 10  8  2  1  8  7  6  0  0  6  2  0], shape=(16,), dtype=int32)\n",
      "Video batch shape: (16, 64, 60, 60, 3)\n",
      "Label batch shape: (16,)\n",
      "tf.Tensor([ 8  4  5  8  0  0  6 11 11  4 10  5  2  8  7  0], shape=(16,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Iterate over the dataset\n",
    "for video, label in dataset.take(5):\n",
    "    print(\"Video batch shape:\", video.shape)  # Should be (batch_size, frames_per_video, height, width, channels)\n",
    "    #print(video)\n",
    "    #plot_video_batch(video, num_frames=frames_per_video, num_rows=8)\n",
    "    print(\"Label batch shape:\", label.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3971a0b-5b94-4568-a8f0-20ea53f1c3a6",
   "metadata": {},
   "source": [
    "### • Data normalization\n",
    "\n",
    "#### Normalize very video in the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab1af1c-03dc-487f-ba63-7e76214bcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization function\n",
    "def normalize_video(video, label):\n",
    "    video = tf.image.convert_image_dtype(video, tf.float32)  # Converts to float32 in range [0, 1]\n",
    "    return video, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e638c0-06af-4312-b5f5-3a0d26a826d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "dataset = dataset.map(normalize_video, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a20124-9f78-49ac-bf22-21433fc57111",
   "metadata": {},
   "source": [
    "### • Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39eba83f-bcbd-4ad9-a33d-8b5983961b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset\n",
    "def split_dataset(dataset, train_split=0.7, val_split=0.15, test_split=0.15, shuffle_buffer_size=1000, dataset_amount = 10000):\n",
    "    # Calculate sizes\n",
    "    dataset_size = dataset_amount # Get total dataset size\n",
    "    train_size = int(train_split * dataset_size)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    print(\"Sizes creados\")\n",
    "    # Shuffle and split\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size, reshuffle_each_iteration=False)\n",
    "    print(\"Shuffle\")\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    print(\"Train take\", dataset_amount)\n",
    "    val_dataset = dataset.skip(train_size).take(val_size)\n",
    "    print(\"Val take\", val_size)\n",
    "    test_dataset = dataset.skip(train_size + val_size)\n",
    "    print(\"Test take\")\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8476a65a-7198-4551-9770-b42037a2c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of videos 1230\n",
      "Sizes creados\n",
      "Shuffle\n",
      "Train take 1230\n",
      "Val take 184\n",
      "Test take\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of videos\", amount_of_videos)\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(dataset, train_split=0.7, val_split=0.15, test_split=0.15, shuffle_buffer_size=1000, dataset_amount = amount_of_videos)\n",
    "\n",
    "# Batch, shuffle, and prefetch\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a6b0d-791f-48c3-9b59-6ee0f47cdb12",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d005c66-0be1-42ee-8a84-25a925460641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_action_detection_model(input_shape=(16, 60, 60, 3), num_classes=101):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Reduced 3D CNN for spatio-temporal feature extraction\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "    # Flatten output and pass through LSTM\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "\n",
    "    # Fully connected layers with fewer units\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48dc38ac-3eac-40c4-bb17-223498bda7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classification model!!!\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 62, 58, 58, 32)    2624      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 62, 58, 58, 32)   128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 62, 29, 29, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 60, 27, 27, 64)    55360     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 60, 27, 27, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 30, 13, 13, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 28, 11, 11, 128)   221312    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 11, 11, 128)  512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 14, 5, 5, 128)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 14, 3200)         0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               3539968   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 101)               25957     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,911,909\n",
      "Trainable params: 3,911,461\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#First we try to load the saved model, if exists we loaded otherwise we create a new one\n",
    "was_action_detection_classification_model_loaded_from_disk = False\n",
    "\n",
    "if os.path.isfile(checkpoints_classification + '/'  + checkpoint_filename_load):\n",
    "    print(\"Loading saved classification model!!!\")\n",
    "    action_detection_model = tf.keras.models.load_model(checkpoints_classification + '/'  + checkpoint_filename_load)\n",
    "    was_action_detection_classification_model_loaded_from_disk = True\n",
    "else:\n",
    "    print(\"Creating classification model!!!\")\n",
    "    action_detection_model = build_action_detection_model(input_shape=(frames_per_video, 60, 60, 3))\n",
    "    \n",
    "action_detection_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff78cb-decd-4974-b2ba-183f5067419b",
   "metadata": {},
   "source": [
    "# *********************** Training phase *************************\n",
    "\n",
    "### We use this common function to train all the architectures of our project, it also creates the checkpoints that we will save for each architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26896dd6-531b-40bd-bc6d-a6e19c66bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_model(model, train_dataset, val_dataset, batch_size=64, epochs=5, checkpoint_dir=''):\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Precision'])\n",
    "\n",
    "    # Create checkpoints folder\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_dir, checkpoint_filename),\n",
    "        save_weights_only=False,  # Save the entire model, not just weights\n",
    "        save_best_only=False,     # Save the model after every epoch, not just the best one\n",
    "        monitor='loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size, validation_data=val_dataset, callbacks=[checkpoint_cb])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea27bc3-de83-4cea-b520-7665911a2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metrics(history, under_lim = -1, upper_lim = 1):\n",
    "    pd.DataFrame(history.history).plot(figsize=(10, 7))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(under_lim, upper_lim)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b34a3f-44c4-46fc-b743-f164727efefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/conv3d/Relu' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\AndreyArguedas\\AppData\\Local\\Temp\\ipykernel_24840\\1672635815.py\", line 2, in <module>\n      history = train_model(action_detection_model, train_dataset, val_dataset, batch_size=batch_size, epochs=5, checkpoint_dir=checkpoints_classification)\n    File \"C:\\Users\\AndreyArguedas\\AppData\\Local\\Temp\\ipykernel_24840\\22140041.py\", line 19, in train_model\n      history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size, validation_data=val_dataset, callbacks=[checkpoint_cb])\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv3d/Relu'\ninput and filter must have the same depth: 60 vs 3\n\t [[{{node sequential/conv3d/Relu}}]] [Op:__inference_train_function_4454]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m was_action_detection_classification_model_loaded_from_disk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_detection_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoints_classification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     visualize_metrics(history)\n",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, val_dataset, batch_size, epochs, checkpoint_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     11\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, checkpoint_filename),\n\u001b[0;32m     12\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Save the entire model, not just weights\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/conv3d/Relu' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\AndreyArguedas\\AppData\\Local\\Temp\\ipykernel_24840\\1672635815.py\", line 2, in <module>\n      history = train_model(action_detection_model, train_dataset, val_dataset, batch_size=batch_size, epochs=5, checkpoint_dir=checkpoints_classification)\n    File \"C:\\Users\\AndreyArguedas\\AppData\\Local\\Temp\\ipykernel_24840\\22140041.py\", line 19, in train_model\n      history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size, validation_data=val_dataset, callbacks=[checkpoint_cb])\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"C:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv3d/Relu'\ninput and filter must have the same depth: 60 vs 3\n\t [[{{node sequential/conv3d/Relu}}]] [Op:__inference_train_function_4454]"
     ]
    }
   ],
   "source": [
    "if was_action_detection_classification_model_loaded_from_disk is False:\n",
    "    history = train_model(action_detection_model, train_dataset, val_dataset, batch_size=batch_size, epochs=5, checkpoint_dir=checkpoints_classification)\n",
    "    visualize_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad82b8-9388-4830-b9f9-57e17bb68f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
